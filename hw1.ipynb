{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqSWE0oAtdvr"
      },
      "source": [
        "# HW 1\r\n",
        "\r\n",
        "Name: Karan Patel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pUFRhgctqFq"
      },
      "source": [
        "## Read and split data into sets\r\n",
        "\r\n",
        "Once the headlines are read, they are split into test, validation and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b12lb2lCt64_",
        "outputId": "fbd0b7a7-30bb-4690-a228-6670f0c57e78"
      },
      "source": [
        "import json\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "raw_data = [eval(line) for line in open ('./drive/MyDrive/Sarcasm_Headlines_Dataset.json', 'r')]\r\n",
        "print('Number of records found = ', len(raw_data))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of records found =  28619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvkBlHDAur2a",
        "outputId": "c9a73821-1bae-41f3-f40e-e88415dfa356"
      },
      "source": [
        "headlines = np.array([doc['headline'] for doc in raw_data])\r\n",
        "labels = np.array([doc['is_sarcastic'] for doc in raw_data])\r\n",
        "\r\n",
        "train_ratio = 0.80\r\n",
        "validation_ratio = 0.10\r\n",
        "test_ratio = 0.10\r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(headlines, labels, test_size=1 - train_ratio, stratify=labels)\r\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test) \r\n",
        "\r\n",
        "print('Headlines in training set = {}, validation set = {}, test set = {}'.format(len(x_train), len(x_val), len(x_test)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headlines in training set = 22895, validation set = 2862, test set = 2862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxV8p4-9w1Yw"
      },
      "source": [
        "## Extract Features from Data\r\n",
        "\r\n",
        "Below, the following three transformers are defined which will assist with extracting various features from the headlines in the data:\r\n",
        "* `NumOfWordsTransformer`: Return word count for a given headline\r\n",
        "* `RepeatingPunctuationsTransformer`: Return counts for repeating punctuations in a given headline. Example: `!!`, `???`\r\n",
        "* `EmoFeaturesTransformer`: Following features are computed by this transformer:\r\n",
        "  * Return a set of features corresponding to the number of words found in the headline that fall under a given \"emotion\" bucket. \r\n",
        "  * Optionally return features that correspond to the emotional intensity of words in headline that fall under a given \"emotion\" bucket. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coelV5HCw6hd"
      },
      "source": [
        "import re\r\n",
        "import csv\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "\r\n",
        "class NumOfWordsTransformer(BaseEstimator, TransformerMixin):\r\n",
        "  \"\"\"\r\n",
        "  return word count for a given headline\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "\r\n",
        "  def fit(self, X, y = None):\r\n",
        "    return self\r\n",
        "\r\n",
        "  def transform(self, X, y = None):\r\n",
        "    word_counter = lambda input: len(re.findall(r'\\w+', input))\r\n",
        "    return [[feature] for feature in list(map(word_counter, X))]\r\n",
        "\r\n",
        "class RepeatingPunctuationsTransformer(BaseEstimator, TransformerMixin):\r\n",
        "  \"\"\"\r\n",
        "  return counts for repeating punctuations in a given headline. Example: !!, ???\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "\r\n",
        "  def fit(self, X, y = None):\r\n",
        "    return self\r\n",
        "\r\n",
        "  def transform(self, X, y = None):\r\n",
        "    repeating_punctuation_counter = lambda input: len(re.findall(r'(([^\\w\\s])\\2+)', input))\r\n",
        "    return [[feature] for feature in list(map(repeating_punctuation_counter, X))]  \r\n",
        "\r\n",
        "class EmoFeaturesTransformer(BaseEstimator, TransformerMixin):\r\n",
        "  \"\"\"\r\n",
        "  Return a set of features corresponding to the number of words found in the headline that fall under a given \"emotion\" bucket.\r\n",
        "  Optionally return features that correspond to the emotional intensity of words in headline that fall under a given \"emotion\" bucket.\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  EMOTIONS = 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust'\r\n",
        "\r\n",
        "  def __init__(self, add_intensity=True):\r\n",
        "    self._emo_lexicon = pd.read_csv('./drive/MyDrive/NRC-Emotion-Intensity-Lexicon-v1.txt', sep='\\t')\r\n",
        "    self._add_intensity = add_intensity\r\n",
        "\r\n",
        "  def fit(self, X, y = None):\r\n",
        "    return self\r\n",
        "\r\n",
        "  def transform(self, X, y = None):\r\n",
        "    return [features for features in list(map(self._get_features, X))]  \r\n",
        "\r\n",
        "  def _get_intensity(self, emo_word, emotion):\r\n",
        "    \"\"\"\r\n",
        "    get intensity for a given word belonging to a given emotion category\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    word_match = self._emo_lexicon['word'] == emo_word\r\n",
        "    emotion_match = self._emo_lexicon['emotion'] == emotion\r\n",
        "\r\n",
        "    return self._emo_lexicon[word_match & emotion_match]['emotion-intensity-score'].iloc[0]\r\n",
        "\r\n",
        "  def _get_features(self, input):\r\n",
        "    feature_list = []\r\n",
        "    input_tokens = input.lower().split()\r\n",
        "\r\n",
        "    for emotion in self.EMOTIONS:\r\n",
        "      word_count = 0\r\n",
        "      intensity = 0\r\n",
        "\r\n",
        "      emo_words = set(self._emo_lexicon.loc[self._emo_lexicon['emotion'] == emotion]['word'])\r\n",
        "      for emo_word in emo_words:\r\n",
        "          if emo_word in input_tokens:\r\n",
        "            word_count += 1\r\n",
        "            intensity += self._get_intensity(emo_word, emotion)\r\n",
        "\r\n",
        "      # add emo word count\r\n",
        "      feature_list.append(word_count)\r\n",
        "      # optionally add emo intensity\r\n",
        "      if self._add_intensity:\r\n",
        "        if word_count != 0:\r\n",
        "          feature_list.append(intensity / word_count)\r\n",
        "        else:\r\n",
        "          feature_list.append(0)\r\n",
        "\r\n",
        "    return feature_list"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYKvL9tQ_7Qc"
      },
      "source": [
        "## Naive Bayes Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0ajXKcMGVWQ"
      },
      "source": [
        "### N-Gram features\r\n",
        "\r\n",
        "The model below uses a combination of unigrams, bigrams and trigrams as features. Note that the best parameters based on parameter selection testing are already hard coded into the model below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuLba1E3Adm2",
        "outputId": "407f8be6-24e4-4f1b-f0e9-9bcb628490ff"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "text_clf_pipeline = Pipeline([\r\n",
        "    ('vect', CountVectorizer(ngram_range=(1, 2))),\r\n",
        "    ('tfidf', TfidfTransformer(use_idf=False)),\r\n",
        "    ('clf', MultinomialNB(alpha=0.01)),\r\n",
        "])\r\n",
        "\r\n",
        "text_clf_pipeline.fit(x_train, y_train)\r\n",
        "\r\n",
        "predicted = text_clf_pipeline.predict(x_test)\r\n",
        "print('Test accuracy = ', np.mean(predicted == y_test))\r\n",
        "\r\n",
        "print('\\nF-score:\\n', metrics.classification_report(y_test, predicted))\r\n",
        "\r\n",
        "scores = cross_val_score(text_clf_pipeline, x_val, y_val, cv=10, scoring='f1_macro')\r\n",
        "print('10-fold cross-validation scores = ', scores)\r\n",
        "print('Average 10-fold cross-validation score = ', sum(scores) / len(scores))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy =  0.8399720475192173\n",
            "\n",
            "F-score:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      1498\n",
            "           1       0.83      0.83      0.83      1364\n",
            "\n",
            "    accuracy                           0.84      2862\n",
            "   macro avg       0.84      0.84      0.84      2862\n",
            "weighted avg       0.84      0.84      0.84      2862\n",
            "\n",
            "10-fold cross-validation scores =  [0.75840867 0.71044987 0.7714953  0.72183151 0.69878697 0.74309375\n",
            " 0.72533859 0.76393047 0.72255173 0.71341622]\n",
            "Average 10-fold cross-validation score =  0.7329303067323467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXaCxWo2CGBq"
      },
      "source": [
        "For the model above, best parameters were selected using `GridSearchCV` as shown below.\r\n",
        "\r\n",
        "__Note__ : For the other three models, I would not be adding code that I used to select best parameters like I did below for the first model. I'm doing so in the interest of time it takes for the code to run and output the result. I'll be talking more about the parameter selection in the written report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6akQv1cCMRo",
        "outputId": "f30f8cf3-3bd7-499b-d22a-faa542c51cce"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = {\r\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)],\r\n",
        "    'tfidf__use_idf': (True, False),\r\n",
        "    'clf__alpha': (1e-2, 1e-3),\r\n",
        "}\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(text_clf_pipeline, parameters, cv=10, n_jobs=-1, scoring='f1_macro')\r\n",
        "\r\n",
        "gs_clf = gs_clf.fit(x_train, y_train)\r\n",
        "print('Best score: ', gs_clf.best_score_)\r\n",
        "\r\n",
        "print('\\nBest parameters:\\n')\r\n",
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score:  0.8401587748236894\n",
            "\n",
            "Best parameters:\n",
            "\n",
            "clf__alpha: 0.01\n",
            "tfidf__use_idf: False\n",
            "vect__ngram_range: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4dPZPOHFaj-"
      },
      "source": [
        "### N-Grams + at-least 3 other features model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL_3xlHSGd3d",
        "outputId": "3614a798-adc2-497a-a207-cc387abd0a63"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.pipeline import FeatureUnion\r\n",
        "\r\n",
        "union = FeatureUnion([('vect', CountVectorizer(ngram_range=(1, 2))),\r\n",
        "                      (\"num-words\", NumOfWordsTransformer()),\r\n",
        "                      (\"repeating-punctuations\", RepeatingPunctuationsTransformer()),\r\n",
        "                      (\"emo-features-transformer\", EmoFeaturesTransformer(add_intensity=True))\r\n",
        "                    ])\r\n",
        "\r\n",
        "text_clf_pipeline = Pipeline([\r\n",
        "    ('union', union),\r\n",
        "    ('tfidf', TfidfTransformer(use_idf=False)),\r\n",
        "    ('clf', MultinomialNB(alpha=0.01)),\r\n",
        "])\r\n",
        "\r\n",
        "text_clf_pipeline.fit(x_train, y_train)\r\n",
        "\r\n",
        "predicted = text_clf_pipeline.predict(x_test)\r\n",
        "print('Test accuracy = ', np.mean(predicted == y_test))\r\n",
        "\r\n",
        "print('\\nF-score:\\n', metrics.classification_report(y_test, predicted))\r\n",
        "\r\n",
        "scores = cross_val_score(text_clf_pipeline, x_val, y_val, cv=10, scoring='f1_macro')\r\n",
        "print('10-fold cross-validation scores = ', scores)\r\n",
        "print('Average 10-fold cross-validation score = ', sum(scores) / len(scores))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy =  0.8483577917540182\n",
            "\n",
            "F-score:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1498\n",
            "           1       0.87      0.80      0.83      1364\n",
            "\n",
            "    accuracy                           0.85      2862\n",
            "   macro avg       0.85      0.85      0.85      2862\n",
            "weighted avg       0.85      0.85      0.85      2862\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10-fold cross-validation scores =  [0.74949905 0.71912312 0.76174668 0.72444219 0.70173521 0.75084628\n",
            " 0.73377518 0.76973784 0.71341622 0.72003012]\n",
            "Average 10-fold cross-validation score =  0.7344351869126358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7AMh_ioHTDO"
      },
      "source": [
        "## SVM Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koTGowRMIYCc"
      },
      "source": [
        "### N-Gram features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwHuTglyIbRl",
        "outputId": "a47633c2-aaee-48b2-f96c-b650000e0412"
      },
      "source": [
        "from sklearn.svm import LinearSVC\r\n",
        "\r\n",
        "text_clf_pipeline = Pipeline([\r\n",
        "    ('vect', CountVectorizer(ngram_range=(1, 2))),\r\n",
        "    ('tfidf', TfidfTransformer(use_idf=True)),\r\n",
        "    ('clf', LinearSVC(loss='squared_hinge')),\r\n",
        "])\r\n",
        "\r\n",
        "text_clf_pipeline.fit(x_train, y_train)\r\n",
        "\r\n",
        "predicted = text_clf_pipeline.predict(x_test)\r\n",
        "print('Test accuracy = ', np.mean(predicted == y_test))\r\n",
        "\r\n",
        "print('\\nF-score:\\n', metrics.classification_report(y_test, predicted))\r\n",
        "\r\n",
        "scores = cross_val_score(text_clf_pipeline, x_val, y_val, cv=10, scoring='f1_macro')\r\n",
        "print('10-fold cross-validation scores = ', scores)\r\n",
        "print('Average 10-fold cross-validation score = ', sum(scores) / len(scores))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy =  0.8626834381551363\n",
            "\n",
            "F-score:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87      1498\n",
            "           1       0.85      0.87      0.86      1364\n",
            "\n",
            "    accuracy                           0.86      2862\n",
            "   macro avg       0.86      0.86      0.86      2862\n",
            "weighted avg       0.86      0.86      0.86      2862\n",
            "\n",
            "10-fold cross-validation scores =  [0.77192425 0.7839695  0.78215146 0.79916473 0.76850625 0.81810176\n",
            " 0.76129222 0.8064405  0.79719288 0.76469577]\n",
            "Average 10-fold cross-validation score =  0.7853439320589615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX_VTNozKGXz"
      },
      "source": [
        "### N-Grams + at-least 3 other features model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhY5evIKKKRS",
        "outputId": "8429a229-4938-4a3c-da0e-88fb2a60488f"
      },
      "source": [
        "from sklearn.svm import LinearSVC\r\n",
        "\r\n",
        "union = FeatureUnion([(\"vect\", CountVectorizer(analyzer='word', ngram_range=(1, 2))),\r\n",
        "                      (\"repeating-punctuations\", RepeatingPunctuationsTransformer()),\r\n",
        "                      (\"emo-features-transformer\", EmoFeaturesTransformer(add_intensity=True))\r\n",
        "                    ])\r\n",
        "\r\n",
        "text_clf_pipeline = Pipeline([\r\n",
        "    ('union', union),\r\n",
        "    ('tfidf', TfidfTransformer(use_idf=True)),\r\n",
        "    ('clf', LinearSVC(loss='squared_hinge')),\r\n",
        "])\r\n",
        "\r\n",
        "text_clf_pipeline.fit(x_train, y_train)\r\n",
        "\r\n",
        "predicted = text_clf_pipeline.predict(x_test)\r\n",
        "print('Test accuracy = ', np.mean(predicted == y_test))\r\n",
        "\r\n",
        "print('\\nF-score:\\n', metrics.classification_report(y_test, predicted))\r\n",
        "\r\n",
        "scores = cross_val_score(text_clf_pipeline, x_val, y_val, cv=10, scoring='f1_macro')\r\n",
        "print('10-fold cross-validation scores = ', scores)\r\n",
        "print('Average 10-fold cross-validation score = ', sum(scores) / len(scores))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy =  0.8654786862334032\n",
            "\n",
            "F-score:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87      1498\n",
            "           1       0.85      0.87      0.86      1364\n",
            "\n",
            "    accuracy                           0.87      2862\n",
            "   macro avg       0.87      0.87      0.87      2862\n",
            "weighted avg       0.87      0.87      0.87      2862\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
			"10-fold cross-validation scores =  [0.82573108 0.78745645 0.77225673 0.79684515 0.75378788 0.77969604\n",
			" 0.78555713 0.8216587  0.80069686 0.82517483]\n",
            "Average 10-fold cross-validation score =  0.7948860857806316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM_0RNw4NQZv"
      },
      "source": [
        "## References\r\n",
        "\r\n",
        "Libraries used:\r\n",
        "* pandas\r\n",
        "* numpy\r\n",
        "* scikit-learn"
      ]
    }
  ]
}