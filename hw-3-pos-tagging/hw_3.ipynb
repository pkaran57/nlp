{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaA8iDk31lWi"
   },
   "source": [
    "# Assignment 3: Parts-of-Speech Tagging \n",
    "\n",
    "Name: Karan Patel  \n",
    "Categorizing and Tagging Words: http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQWwtmYe2HrY",
    "outputId": "f3b259f2-55fa-4ec8-f183-5514438bb11f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\r631915\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\r631915\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\r631915\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\r631915\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from IPython.display import HTML, display\n",
    "from tabulate import tabulate\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SP1OSqQ11R0"
   },
   "source": [
    "__Q1.__ Search the web for 2 “spoof newspaper headlines”, to find such gems as: _British Left Waffles on Falkland Islands_, and _Juvenile Court to Try Shooting Defendant_. Manually tag these headlines to see if knowledge of the part-of-speech tags removes the ambiguity.\n",
    "\n",
    "__Answer__: \n",
    "\n",
    "Following are the two spoof newspaper headlines that I found from the web and my corresponding manual pos tagging:\n",
    "1. Cows lose their jobs as milk prices drop \n",
    "\n",
    "> Cows (noun) lose (verb) their (pronoun) jobs (noun) as(preposition) milk (pronoun) prices (noun) drop (verb).\n",
    "\n",
    "2. Trump's Lawyers: Telling Armed Crazies to \"Go to Capitol\" and \"Fight Like Hell\" Was Just Metaphorical\n",
    "\n",
    "> Trump's (noum) Lawyers (noun): Telling (adverb) Armed (verb) Crazies (noun) to (preposition) \"Go (verb) to (preposition) Capitol (noun)\" and (preposition) \"Fight (verb) Like (adjective) Hell (noun)\" Was (noun) Just (preposition) Metaphorical (noun)\n",
    "\n",
    "Below, the headlines are tagged using `nltk`. It definitely helps remove a lot of ambiguity that I had when manually tagging the headlines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cG1uvmv2GjV",
    "outputId": "d84a39b6-e824-4a09-e08e-b95ae9d5eeb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags for headline #1:\n",
      "[('Cows', 'NOUN'), ('lose', 'VERB'), ('their', 'PRON'), ('jobs', 'NOUN'), ('as', 'ADP'), ('milk', 'NOUN'), ('prices', 'NOUN'), ('drop', 'NOUN')]\n",
      "\n",
      "POS tags for headline #2:\n",
      "[('Trump', 'NOUN'), (\"'s\", 'PRT'), ('Lawyers', 'NOUN'), (':', '.'), ('Telling', 'NOUN'), ('Armed', 'NOUN'), ('Crazies', 'NOUN'), ('to', 'PRT'), ('``', '.'), ('Go', 'VERB'), ('to', 'PRT'), ('Capitol', 'NOUN'), (\"''\", '.'), ('and', 'CONJ'), ('``', '.'), ('Fight', 'NOUN'), ('Like', 'ADP'), ('Hell', 'NOUN'), (\"''\", '.'), ('Was', 'NOUN'), ('Just', 'NOUN'), ('Metaphorical', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(\"Cows lose their jobs as milk prices drop\")\n",
    "print(\"POS tags for headline #1:\\n{}\\n\".format(nltk.pos_tag(tokens, tagset='universal')))\n",
    "\n",
    "tokens = nltk.word_tokenize('Trump\\'s Lawyers: Telling Armed Crazies to \"Go to Capitol\" and \"Fight Like Hell\" Was Just Metaphorical')\n",
    "print(\"POS tags for headline #2:\\n{}\".format(nltk.pos_tag(tokens, tagset='universal')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3NnAzBg2uol"
   },
   "source": [
    "__Q2.__ Tokenize and tag the following sentence: They wind back the clock, while we chase after the wind. What is the output?\n",
    "\n",
    "__Answer__: The output is a list of tuples of words in sentence and their corresponding part of speech (pos) tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnR_apph6wUw",
    "outputId": "7911e6ee-2f10-453d-eb90-58fa031faf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags for sentence:\n",
      "[('They', 'PRP'), ('wind', 'VBP'), ('back', 'RB'), ('the', 'DT'), ('clock', 'NN'), (',', ','), ('while', 'IN'), ('we', 'PRP'), ('chase', 'VBP'), ('after', 'IN'), ('the', 'DT'), ('wind', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize('They wind back the clock, while we chase after the wind.')\n",
    "print(\"POS tags for sentence:\\n{}\".format(nltk.pos_tag(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6moIgAI92yvx"
   },
   "source": [
    "__Q3.__ Pick 2 words that can be either a noun or a verb (e.g., contest). Predict which POS tag is likely to be the most frequent in the Brown corpus, and compare with your predictions.\n",
    "\n",
    "__Answer:__ Following are the 2 words (that can be either a noun or a verb) that I picked:\n",
    "1. increase  \n",
    "    - My prediction of most likely POS tag between Noun or Verb: Verb\n",
    "    - Actual: Noun\n",
    "2. attack  \n",
    "    - My prediction of most likely POS tag between Noun or Verb: Verb\n",
    "    - Actual: Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of when \"increase\" is noun = 112\n",
      "Counts of when \"increase\" is verb = 82\n",
      "\n",
      "Counts of when \"attack\" is noun = 78\n",
      "Counts of when \"attack\" is verb = 24\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'increase'\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown.tagged_words(tagset='universal') if word == word_1)\n",
    "print('Counts of when \"{}\" is noun = {}'.format(word_1, tag_fd['NOUN']))\n",
    "print('Counts of when \"{}\" is verb = {}'.format(word_1, tag_fd['VERB']))\n",
    "\n",
    "word_2 = 'attack'\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown.tagged_words(tagset='universal') if word == word_2)\n",
    "print('\\nCounts of when \"{}\" is noun = {}'.format(word_2, tag_fd['NOUN']))\n",
    "print('Counts of when \"{}\" is verb = {}'.format(word_2, tag_fd['VERB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjkN-f5A22v1"
   },
   "source": [
    "__Q4.__ Use sorted() and set() to get a sorted list of tags used in the Brown corpus, removing duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(tag for (word, tag) in brown.tagged_words(tagset='universal')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q5.__ Write programs to process the Brown Corpus and find answers to the following questions:\n",
    "1. Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.)\n",
    "\n",
    "__Answer:__ My program found a total of 822 nouns that are more common in their plural form, rather than their singular form. Some of the examples are shown by the output of the code. For example, noun \"painting\" (with a singlualr count of 27) is more common in its plural form \"paintings\" (with a plural count of 34)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 23187 singular nouns in the corpus.\n",
      "\n",
      "(Singluar) noun \"painting\" is more common in its plural form \"paintings\". Singular form count = 27, plural form count = 34\n",
      "(Singluar) noun \"pledge\" is more common in its plural form \"pledges\". Singular form count = 2, plural form count = 3\n",
      "(Singluar) noun \"bound\" is more common in its plural form \"bounds\". Singular form count = 3, plural form count = 10\n",
      "(Singluar) noun \"customer\" is more common in its plural form \"customers\". Singular form count = 23, plural form count = 37\n",
      "(Singluar) noun \"cart\" is more common in its plural form \"carts\". Singular form count = 4, plural form count = 5\n",
      "(Singluar) noun \"requirement\" is more common in its plural form \"requirements\". Singular form count = 27, plural form count = 78\n",
      "(Singluar) noun \"alloy\" is more common in its plural form \"alloys\". Singular form count = 2, plural form count = 3\n",
      "(Singluar) noun \"loyalist\" is more common in its plural form \"loyalists\". Singular form count = 1, plural form count = 2\n",
      "(Singluar) noun \"2-year-old\" is more common in its plural form \"2-year-olds\". Singular form count = 2, plural form count = 3\n",
      "(Singluar) noun \"cuff\" is more common in its plural form \"cuffs\". Singular form count = 1, plural form count = 2\n",
      "(Singluar) noun \"striving\" is more common in its plural form \"strivings\". Singular form count = 1, plural form count = 3\n",
      "\n",
      "Found a total of 822 nouns that are more common in their plural form, rather than their singular form. Only showing a few above.\n"
     ]
    }
   ],
   "source": [
    "# Q5.1\n",
    "\n",
    "# Note: foreign word noun tags are excluded from sets below since plural foreign words may not have a '-s' suffix\n",
    "singular_noun_tags = {'NN', 'NN$', 'NN+BEZ', 'NN+HVD', 'NN+HVZ', 'NN+IN', 'NN+MD', 'NN+NN', 'NP', 'NP$', 'NP+BEZ', 'NP+HVZ', 'NP+MD', 'NR', 'NP$', 'NR+MD'}\n",
    "plural_noun_tags = {'NNS', 'NNS$', 'NNS+MD', 'NPS', 'NPS$', 'NRS'}\n",
    "\n",
    "singular_noun_freq_dist = nltk.FreqDist(word for (word, tag) in brown.tagged_words() if tag in singular_noun_tags)\n",
    "all_singular_nouns = set(singular_noun_freq_dist.keys())\n",
    "print(f'Found a total of {len(all_singular_nouns)} singular nouns in the corpus.\\n')\n",
    "\n",
    "all_regular_plural_nouns = {singular_noun + 's' for singular_noun in all_singular_nouns}\n",
    "plural_noun_freq_dist = nltk.FreqDist(word for (word, tag) in brown.tagged_words() if tag in plural_noun_tags and word in all_regular_plural_nouns)\n",
    "\n",
    "total_count = 0\n",
    "for singluar_noun in all_singular_nouns:\n",
    "    plural_noun = singluar_noun + 's'\n",
    "    \n",
    "    singular_noun_count = singular_noun_freq_dist[singluar_noun]\n",
    "    plural_noun_count = plural_noun_freq_dist[plural_noun]\n",
    "    \n",
    "    if plural_noun_count > singular_noun_count:\n",
    "        if total_count <= 10:\n",
    "            print(f'(Singluar) noun \"{singluar_noun}\" is more common in its plural form \"{plural_noun}\". Singular form count = {singular_noun_count}, plural form count = {plural_noun_count}')\n",
    "        total_count += 1\n",
    "\n",
    "print(f'\\nFound a total of {total_count} nouns that are more common in their plural form, rather than their singular form. Only showing a few above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q5.2.__ List tags in order of decreasing frequency. What do the 20 most frequent tags represent?\n",
    "\n",
    "__Answer:__ The 20 most frequent tags represent top 20 part of speech tags that appeared the most in the brown corpus. My code below prints out the counts associated with each pos tag. Words with those pos tags are the most frequent in the corpus. \n",
    "\n",
    "Looking at the 20 most frequent tags, it looks like singluar nouns and prepositions are the most common POS tags. Period (.) and comma (,) also are relatively very frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 152470), ('IN', 120557), ('AT', 97959), ('JJ', 64028), ('.', 60638), (',', 58156), ('NNS', 55110), ('CC', 37718), ('RB', 36464), ('NP', 34476), ('VB', 33693), ('VBN', 29186), ('VBD', 26167), ('CS', 22143), ('PPS', 18253), ('VBG', 17893), ('PP$', 16872), ('TO', 14918), ('PPSS', 13802), ('CD', 13510)]\n"
     ]
    }
   ],
   "source": [
    "# Q5.2\n",
    "\n",
    "tags_frequency_dist = nltk.FreqDist(tag for (word, tag) in brown.tagged_words())\n",
    "print(tags_frequency_dist.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q6.__ Generate some statistics for tagged data to answer the following questions: \n",
    "1. What proportion of word types are always assigned the same part-of-speech tag?  \n",
    "__Answer__: 84.42834971546819 % of the words are always assigned the same part-of-speech tag.\n",
    "2. How many words are ambiguous, in the sense that they appear with at least two tags?  \n",
    "__Answer__: 8729 words are ambiguous.\n",
    "3. What percentage of word tokens in the Brown Corpus involve these ambiguous words?  \n",
    "__Answer__: % of word tokens that involve ambiguous words = 78.64892283102192 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of work tokens = 1161192\n",
      "Found a total of 56057 word types / unique words.\n",
      "Found a total of 472 POS tags.\n",
      "\n",
      "% of word types that are always assigned the same part-of-speech tag = 84.42834971546819 %\n",
      "Number of words that are ambiguous (i.e. they appear with at least two tags) = 8729\n",
      "% of word tokens that involve ambiguous words = 78.64892283102192 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_word_tokens = len(brown.words())\n",
    "print(f'Number of work tokens = {num_word_tokens}')\n",
    "\n",
    "all_word_types = {word for word in brown.words()}\n",
    "print(f'Found a total of {len(all_word_types)} word types / unique words.')\n",
    "\n",
    "all_pos_tags = {tag for (word, tag) in brown.tagged_words()}\n",
    "print(f'Found a total of {len(all_pos_tags)} POS tags.\\n')\n",
    "\n",
    "word_types_with_unique_pos_tag_assignment_count = 0\n",
    "num_ambiguous_words = 0\n",
    "ambiguous_word_tokens_count = 0\n",
    "\n",
    "word_type_to_pos_tags_dict = {word_type:set() for word_type in all_word_types}\n",
    "for word_token, tag in brown.tagged_words():\n",
    "    word_type_to_pos_tags_dict[word_token].add(tag)\n",
    "    \n",
    "for word_type, pos_tags_set in word_type_to_pos_tags_dict.items():\n",
    "    if len(pos_tags_set) == 1:\n",
    "        word_types_with_unique_pos_tag_assignment_count += 1\n",
    "    elif len(pos_tags_set) > 1:\n",
    "        num_ambiguous_words += 1\n",
    "\n",
    "for word_token in brown.words():\n",
    "    if len(word_type_to_pos_tags_dict[word_token]) > 1:\n",
    "        ambiguous_word_tokens_count += 1\n",
    "        \n",
    "print(f'% of word types that are always assigned the same part-of-speech tag = {(word_types_with_unique_pos_tag_assignment_count / len(all_word_types)) * 100} %')\n",
    "print(f'Number of words that are ambiguous (i.e. they appear with at least two tags) = {num_ambiguous_words}')\n",
    "print(f'% of word tokens that involve ambiguous words = {(ambiguous_word_tokens_count / num_word_tokens) * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q9.__ There are 264 distinct words in the Brown Corpus having exactly three possible tags.\n",
    "1. Print a table with the integers 1..10 in one column, and the number of distinct words in the corpus having 1..10 distinct tags in the other column.\n",
    "2. For the word with the greatest number of distinct tags, print out sentences from the corpus containing the word, one for each possible tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Num. of distinct tags</th><th style=\"text-align: right;\">  Num. of distinct words</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">                   47328</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      2</td><td style=\"text-align: right;\">                    7186</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      3</td><td style=\"text-align: right;\">                    1146</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      4</td><td style=\"text-align: right;\">                     265</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      5</td><td style=\"text-align: right;\">                      87</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      6</td><td style=\"text-align: right;\">                      27</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      7</td><td style=\"text-align: right;\">                      12</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      8</td><td style=\"text-align: right;\">                       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                      9</td><td style=\"text-align: right;\">                       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                     10</td><td style=\"text-align: right;\">                       2</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"that\" is the word with the greatest number of distinct tags (12). Here are all distinct pos tags found: {'WPO', 'WPO-NC', 'NIL', 'WPS', 'CS-HL', 'DT-NC', 'CS', 'QL', 'WPS-NC', 'CS-NC', 'DT', 'WPS-HL'}\n",
      "\n",
      "\n",
      "For WPO tag, sentence = He was able to smell a bargain -- and a masterpiece -- a continent away , and the Museum of Modern Art's Alfred Barr said of him : `` I have never mentioned a new artist that Thompson didn't know about '' .\n",
      "\n",
      "For WPO-NC tag, sentence = Thus to has light stress both in that was the conclusion that I came to and in that was the conclusion I came to .\n",
      "\n",
      "For NIL tag, sentence = Thus , as a development program is being launched , commitments and obligations must be entered into in a given year which may exceed by twofold or threefold the expenditures to be made in that year .\n",
      "\n",
      "For WPS tag, sentence = Regarding Atlanta's new multi-million-dollar airport , the jury recommended `` that when the new management takes charge Jan. 1 the airport be operated in a manner that will eliminate political influences '' .\n",
      "\n",
      "For CS-HL tag, sentence = According to the official interpretation of the Charter , a member cannot be penalized by not having the right to vote in the General Assembly for nonpayment of financial obligations to the `` special '' United Nations' budgets , and of course cannot be expelled from the Organization ( which you suggested in your editorial ) , due to the fact that there is no provision in the Charter for expulsion .\n",
      "\n",
      "For DT-NC tag, sentence = He has his own system of shorthand , devised by abbreviations : `` humility '' will be `` humly '' , `` with '' will be `` w '' , and `` that '' will be `` tt '' .\n",
      "\n",
      "For CS tag, sentence = The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "\n",
      "For QL tag, sentence = While the city council suggested that the Legislative Council might perform the review , Mr. Notte said that instead he will take up the matter with Atty. Gen. J. Joseph Nugent to get `` the benefit of his views '' .\n",
      "\n",
      "For WPS-NC tag, sentence = In of all the suggestions that were made , his was the silliest the possessive his represents his suggestion and is stressed .\n",
      "\n",
      "For CS-NC tag, sentence = But when to represents to consciousness in that was the moment that I came to , and similarly in that was the moment I came to , there is much stronger stress on to .\n",
      "\n",
      "For DT tag, sentence = `` Actually , the abuse of the process may have constituted a contempt of the Criminal court of Cook county , altho vindication of the authority of that court is not the function of this court '' , said Karns , who is a City judge in East St. Louis sitting in Cook County court .\n",
      "\n",
      "For WPS-HL tag, sentence = Factors that inhibit learning and lead to maladjustment\n"
     ]
    }
   ],
   "source": [
    "all_word_types = {word for word in brown.words()}\n",
    "word_type_to_pos_tags_dict = {word_type:set() for word_type in all_word_types}\n",
    "for word_token, tag in brown.tagged_words():\n",
    "    word_type_to_pos_tags_dict[word_token].add(tag)\n",
    "\n",
    "distinct_pos_tag_count_to_distinct_words_count = {i + 1:0 for i in range(10)}\n",
    "word_to_distinct_pos_tags_count = (None, 0)  # word, distinct pos tags count\n",
    "for word, pos_tags_set in word_type_to_pos_tags_dict.items():\n",
    "    num_unique_tags = len(pos_tags_set)\n",
    "    \n",
    "    if num_unique_tags > 0 and num_unique_tags <= 10:\n",
    "        distinct_pos_tag_count_to_distinct_words_count[num_unique_tags] = distinct_pos_tag_count_to_distinct_words_count[num_unique_tags] + 1\n",
    "    \n",
    "    if num_unique_tags > word_to_distinct_pos_tags_count[1]:\n",
    "        word_to_distinct_pos_tags_count = word, num_unique_tags\n",
    "\n",
    "display(HTML(tabulate([(pos_int, count) for (pos_int, count) in distinct_pos_tag_count_to_distinct_words_count.items()], headers=['Num. of distinct tags', 'Num. of distinct words'], tablefmt='html')))\n",
    "\n",
    "\n",
    "print(f'\\n\"{word_to_distinct_pos_tags_count[0]}\" is the word with the greatest number of distinct tags ({word_to_distinct_pos_tags_count[1]}). Here are all distinct pos tags found: {word_type_to_pos_tags_dict[word_to_distinct_pos_tags_count[0]]}\\n')\n",
    "\n",
    "for tag in word_type_to_pos_tags_dict[word_to_distinct_pos_tags_count[0]]:\n",
    "    for tagged_sentence in brown.tagged_sents():\n",
    "        if (word_to_distinct_pos_tags_count[0], tag) in tagged_sentence:\n",
    "            sentence = ' '.join([word for word, tag in tagged_sentence])\n",
    "            print(f'\\nFor {tag} tag, sentence = {sentence}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q8__: How serious is the sparse data problem? Investigate the performance of n-gram taggers as n increases from 1 to 6. Tabulate the accuracy score.\n",
    "\n",
    "__Answer__: Based on the accuray score, the sparse data problem seems to be pretty serious for when n is larger than 2. The accuracy scores drop off significantly for n-gram taggers after n is larger than 2. \n",
    "\n",
    "The size of an n-gram table increases significantly with increasing `n` variable with the large table having lots of unfilled/empty array cells. Also, as n gets larger,  the specificity of the contexts increases further impacting the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  N-Grams</th><th style=\"text-align: right;\">  Accuracy Score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">        0.884935</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">        0.351575</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">        0.202971</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">        0.152511</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        5</td><td style=\"text-align: right;\">        0.1402  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        6</td><td style=\"text-align: right;\">        0.138367</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents()\n",
    "\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "table = []\n",
    "for i in range(6):\n",
    "    n = i + 1\n",
    "    n_gram_tagger = nltk.NgramTagger(n, train=train_sents)\n",
    "    \n",
    "    row = n, n_gram_tagger.evaluate(test_sents)\n",
    "    table.append(row)\n",
    "\n",
    "display(HTML(tabulate(table, headers=['N-Grams', 'Accuracy Score'], tablefmt='html')))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
